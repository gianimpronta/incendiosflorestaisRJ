---
title: "Análise Preditiva de Incêndios Florestais no Estado do RJ"
output:
  html_document:
    df_print: paged
---
```{r setup, echo=FALSE}
knitr::opts_chunk$set(cache = TRUE)
knitr::opts_chunk$set(comment = " ")

```

Carregando Bibliotecas:

```{r bibliotecas, message=FALSE}
library(tidyverse)
library(reshape2)
library(ggplot2)
library(mice)
library(data.table)
library(ggmap)
library(Hmisc)
library(corrplot)
library(geosphere)
library(rattle)
library(caret)
library(maps)
library(mapdata)
library(caretEnsemble)
library(DT)
library(parallel)
library(doParallel)
library(DMwR)
library(ROSE)
```


# __Objetivos__

Está analise consiste na utilização de observações de queimadas e incêndios florestais feitas pelo INPE 
(Instituto Nacional de Pesquisas Espaciais) em conjunto com observações de estações meteorológicas convencionais do INMET( Instituto Nacional de Meteorologia) na tentativa de obter correlações entre as queimadas e incêndios florestais e as condições meteorológicas de forma a predizer quando ocorrerá um evento.


# __Base de dados__
## __Conjunto de dados: Focos__

Foi utilizada um série temporal extraída do Banco de Dados de queimadas do INPE (<https://prodwww-queimadas.dgi.inpe.br/bdqueimadas>) no formato CSV contendo dados do dia 01/01/2010 até 31/12/2016 com as seguintes colunas:

- DataHora - Data e hora da detecção do foco
- Satelite - Nome do satélite de referência
- Pais - País da detecção
- Estado - estado da detecção
- Municipi - município da detecção
- Bioma - bioma da detecção
- DiaSemCh - A quantos dias a referida área está sem chuvas
- Precipit - Precipitação no momento da detecção
- RiscoFog - Risco de Fogo calculado para a área
- Latitude - Latitude do foco
- Longitud - Longitude do foco
- AreaIndu - Determina se a área do foco é industrial
- FRP - Potência Radiativa do Fogo

O Dataset possui alguns focos duplicados, o que se deve ao fato de vários satélites detectarem o mesmo foco de queimada.
Dimensões do conjunto de dados - 8.618.991 linhas e 13 colunas

```{r sumario focos}
load(file = "./dados/focos(bruto).RData")
summary(focos)    
```

## __Conjunto de dados: Meteorologia__

Foram utilizados dados de estações meteorológicas convencionais obtidos através do Banco de Dados Meteorológicos para Ensino e Pesquisa (<http://www.inmet.gov.br/projetos/rede/pesquisa/>) contendo uma série temporal do dia 01/01/2010 ao dia 31/12/2016.

- Estacao – Código da estação convencional
- Data – Data da medição
- Hora – Hora da medição
- TempBulboSeco – temperatura medida com termômetro de bulbo seco
- TempBulboUmido – temperatura medida com termômetro de bulbo úmido
- UmidadeRelativa – umidade relativa do ar
- PressaoAtmEstacao – pressão atmosférica no nível da estação
- VelocidadeVento – velocidade do vento no momento da medição
- Nebulosidade – nebulosidade no momento da medição
- Latitude – Latitude da estação
- Longitude – Longitude da estação

Dimensões do conjunto de dados – 1.781.719 linhas e 11 colunas

```{r sumario meteo}
load(file = "./dados/meteo(bruto).RData")
summary(meteo)
```

# __Pré-processamento__
## Seleção dos dados

O conjunto de dados Focos não utilizará as colunas “AreaIndu” e “FRP” pois as mesmas estão vazias e não utilizará também a coluna “Pais” já todos os dados se referem apenas ao Brasil.

O dois conjuntos serão filtrados para conterem somente os dados referentes ao estado do Rio de Janeiro. O conjunto focos será filtrado pela coluna Estado, a qual poderá ser removida justamente pois se tornará redundante. O conjunto meteo será filtrado através das estações 83738, 83049, 83743, 83718, 83698 e 83695 localizadas respectivamente em Resende, Paty do Alferes, Rio de janeiro, Cordeiro, Campos dos Goytacazes e Itaperuna, a localização das estações foi obtida através do site do INMET. 

```{r filtragem focos}
focos_rj <- focos %>%
    filter(Estado == "Rio de Janeiro") %>%
    select(-Estado)

100-(dim(focos_rj)[1]/dim(focos)[1]*100)

```

A primeira filtragem do conjunto focos reduziu o número de observações de 8.618.991 para apenas 23.224, uma redução de 99.73% do dataset.

```{r filtragem meteo}
meteo_rj <- meteo %>%
    filter(Estacao == 83049 | Estacao == 83738 | Estacao ==  83743 | 
               Estacao == 83718 | Estacao == 83698 | Estacao == 83695) %>%
    mutate(mes = as.numeric(format(.[["Data"]], "%m")), ano = as.numeric(format(.[["Data"]], "%Y")))
100-(dim(meteo_rj)[1]/dim(meteo)[1]*100)
```

A primeira filtragem do conjunto meteo reduziu o número de observações de 1.781.719 para apenas 42.546, uma redução de 97.61% do dataset, além disso foram acrescentadas duas colunas, "mes" e "ano".

## Qualidade e Limpeza dos dados

### Limpeza do conjunto de dados Meteo
#### Verificando as observações faltantes
```{r verificando NA meteo}
sapply(meteo_rj, function(x)(sum(is.na(x))))
```

#### Checando a frequência das estações por ano
```{r frequencia estacos ano}
freq_table <- xtabs(~ano+Estacao, data=meteo_rj) %>% 
      t(.)
freq_table <- reshape(as.data.frame(freq_table), timevar = "ano", idvar = "Estacao", direction = "wide")
head(freq_table[which(freq_table == 0, arr.ind = TRUE)[,1],])
```

Todas as estações tem dados para todos os anos.

#### Distribuição de Valores faltantes por ano
```{r distribuição valores faltantes por ano}
aggregate(. ~ ano, data=meteo_rj, function(x) {sum(is.na(x))}, na.action = NULL) %>%
      melt(id.vars = "ano") %>% 
      filter (value > 0) %>%
      ggplot(data = . , aes(variable, value, fill = variable)) + 
      geom_bar(stat = "identity") + facet_grid(ano ~ .) + 
      theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

#### Distribuição de valores faltantes por estação
```{r valores faltantes por estação, options}
meteo_rj$Estacao <- as.factor(meteo_rj$Estacao)
aggregate(. ~ Estacao, data=meteo_rj, function(x) {sum(is.na(x))}, na.action = NULL) %>%
      melt() %>%
      filter(value > 0) %>%
      ggplot(data = . , aes(variable, value, fill = variable)) + 
      geom_bar(stat = "identity") + facet_grid(Estacao ~ .) + 
      theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
```{r NA estacao 83049}
paste("Valores faltantes:", 
      sum(is.na(meteo_rj[meteo_rj$Estacao == 83049, "PressaoAtmEstacao"])))
paste("Total de observações:", dim(meteo_rj[meteo_rj$Estacao == 83049, ])[1])
```

Podemos perceber que a estação 83049 possui todas observações para PressaoAtm vazias, desse modo, para que a análise não seja muito prejudicada, excluíremos essa coluna.

```{r retirando PressaoAtmEstacao}
meteo_rj$PressaoAtmEstacao <- NULL
names(meteo_rj)
```

```{r NA estacao 83743}
paste("Valores faltantes:", 
      sum(is.na(meteo_rj[meteo_rj$Estacao == 83743, "VelocidadeVento"])))
paste("Total de observações:", dim(meteo_rj[meteo_rj$Estacao == 83743, ])[1])
```

Podemos perceber que a estação 83743 apesar de ter um grande número de valores faltantes na coluna VelocidadeVento, a maior parte das observações está lá. 
Utilizaremos o pacote MICE para realizar a imputação dos dados faltantes.

#### Imputação dos valores faltantes através de imputação multivariada por equações em cascata (pacote mice)

```{r imputação meteo, eval= FALSE}
ini <- meteo_rj %>%
      select(c("TempBulboSeco", "TempBulboUmido", "VelocidadeVento", 
               "UmidadeRelativa", "Nebulosidade")) %>%
      mice(data = ., maxit = 0, seed = 1869)

imp_merged <- mice.mids(ini, maxit = 3)
meteo_rj_imputado <- complete(imp_merged)
```
```{r carregando meteo_rj_imputado, echo= FALSE}
load("./dados/meteo_rj_imputado.rds")
```

#### Comparando a distribuição das variáveis antes e depois da imputação. 
```{r comparando imputação, fig.height= 9}
# Pequena função para auxiliar na plotagem
plot.multi.dens <- function(s)
{
      junk.x = NULL
      junk.y = NULL
      for(i in 1:length(s)) {
            junk.x = c(junk.x, density(s[[i]])$x)
            junk.y = c(junk.y, density(s[[i]])$y)
      }
      xr <- range(junk.x)
      yr <- range(junk.y)
      plot(density(s[[1]]), xlim = xr, ylim = yr, main = "")
      for(i in 1:length(s)) {
            lines(density(s[[i]]), xlim = xr, ylim = yr, col = i)
      }
}

par(mfrow = c(3, 2))
for (i in names(meteo_rj_imputado)){
      plot.multi.dens(list(cc(meteo_rj[[i]]), meteo_rj_imputado[[i]]))      
}
```


#### Substituindo os valores antigos pelos novos
```{r finalizando pré processamento meteo}
for ( i in names(meteo_rj_imputado)){
      meteo_rj[[i]] <- meteo_rj_imputado[[i]]
}
rm("meteo", "meteo_rj_imputado", freq_table)
```




### Limpeza do conjuto Focos

#### Checando a existência de valores faltantes
```{r valores faltantes focos}
paste("Valores faltantes:", sum(is.na(focos_rj)))
```

#### Criando Colunas

Criando duas colunas, "mes" e "ano" para facilitar a análise.
```{r Criano ano e mes}
focos_rj <- focos_rj %>% 
      mutate(mes = format(DataHora, "%m"), 
             ano = format(DataHora, "%Y"))
rm(focos)
```

#### Checando formatos das colunas
```{r colunas focos, options}
str(focos_rj)
```

## Análise exploratória

### Focos

Distibuição das queimadas ao longo do ano, da Latitude e Longitude
```{r AED Focos, options}
# Carregando script para realizar o multiplot
source("scripts/multiplot.R")
p1 <- qplot(focos_rj$mes, xlab = "Mês do ano")
p2 <- qplot(focos_rj$Latitude, binwidth = 0.1, xlab = "Latitude")
p3 <- qplot(focos_rj$Longitude, binwidth = 0.1, xlab = "Longitude")
multiplot(p1,p2,p3)
```

Locais com maior incidência de focos de queimadas.
```{r heatmap focos, message=FALSE}
BB <- c(min(focos_rj$Longitude - 0.1), min(focos_rj$Latitude - 0.1), 
        max(focos_rj$Longitude + 0.1), max(focos_rj$Latitude + 0.1))
figure <- ggmap(get_map( location = BB, source = "stamen",  maptype = "toner-lite") )
figure + 
      geom_density2d(data = focos_rj, aes(x = Longitude, y = Latitude), size = 0.01) + 
      stat_density2d(data = focos_rj, aes(x = Longitude, y = Latitude, fill = ..level.., alpha = ..level..), size = 0.01, 
    bins =16, geom = "polygon") + 
      scale_fill_gradientn(colors = heat.colors(16), guide = FALSE) + 
    scale_alpha(range = c(0.1, 0.8), guide = FALSE)
```

```{r label, options}
p1 <- qplot(focos_rj$DiasSemChuva, xlab = "Dias Sem Chuva", bins = 30)
p2 <- qplot(focos_rj$Precipitacao, xlab = "Precipitação", bins = 100)
p3 <- qplot(focos_rj$RiscoFogo, xlab = " RiscoFogo", bins = 30)
p4 <- focos_rj %>%
  group_by(Municipio) %>%
  summarise(count = n()) %>%
  mutate(Municipio = factor(.$Municipio, levels = .$Municipio[order(-.$count)])) %>%
  top_n(10) %>%
  ggplot(data = ., aes(x = Municipio, y = count)) + 
    geom_bar(stat = "identity") +
    theme_grey() + theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8))
multiplot(p1,p2,p3,p4, cols = 2)
```

De cima para baixo em sentido horário a partir da esquerda:

- Distribuição da quantidade de dias sem chuva no momento do incendio;
- Distribuição do Risco de Fogo no momento dos incêndios;
- 10 Municípios com maior quantidade de incêndios;
- Distribuição da precipitação no dia dos incêndios

### Meteo

Variação da temperatura medida com termômetro de bulbo seco ao longo do ano por estação.
```{r AED meteo}
ggplot(data = meteo_rj, aes(x = mes, y = TempBulboSeco, group = mes)) +
      geom_boxplot(color = "black", fill = "#189ad3") + 
      facet_grid(. ~ Estacao) + 
      theme_grey() + theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 7))
```

Variação da temperatura medida com termômetro de bulbo úmido ao longo do ano por estação.

```{r Bulbo umido por ano, options}
ggplot(data = meteo_rj, aes(x = mes, y = TempBulboUmido, group = mes)) +
      geom_boxplot(color = "black", fill = "#189ad3") + 
      facet_grid(. ~ Estacao) + 
      theme_grey() + theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 7))
```

Variação das diferentes tempeturas de diferentes termômetros.
```{r Violin plot temp, options}
ggplot(data = melt(meteo_rj[,c(1,4:5)], id.vars = "Estacao"), aes(x = variable, y = value, fill = variable)) +
      geom_violin(draw_quantiles = c(.25,.5,.75), scale = "area") + 
      facet_grid(. ~ Estacao) + 
      theme_grey() + theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 9))
```

Variação da umidade relativa ao longo do ano por estação
```{r Umidade por ano, options}
ggplot(data = meteo_rj, aes(x = mes, y = UmidadeRelativa, group = mes)) +
      geom_boxplot(color = "black", fill = "#189ad3") + 
      facet_grid(. ~ Estacao) + 
      theme_grey() + theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 7))
```

Variação da velocidade do vento ao longo do ano por estação
```{r velocidade do vento por ano, options}
ggplot(data = meteo_rj, aes(x = mes, y = VelocidadeVento, group = mes)) +
      geom_boxplot(color = "black", fill = "#189ad3") + 
      facet_grid(. ~ Estacao) + 
      theme_grey() + theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 7))
```

Variação da nebulosidade ao longo do ano por estação
```{r Nebuloside por ano, options}
ggplot(data = meteo_rj, aes(x = mes, y = Nebulosidade, group = mes)) +
      geom_boxplot(color = "black", fill = "#189ad3") + 
      facet_grid(. ~ Estacao) + 
      theme_grey() + theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 7))
```



Localização das estações meteorológicas
```{r Localização das estações, message=FALSE, warning=FALSE}
estacoes = unique(meteo_rj[,c(1, 9, 10)])
figure2 <- ggmap(get_map( location = BB, source = "stamen",  maptype = "toner-lite") ) 
figure2 + 
  geom_point(data = estacoes, aes(x= Longitude, y = Latitude), color = "red", size = 4, alpha = 0.6) +
  geom_label(data = estacoes, aes(label = paste("Estação", Estacao), x = Longitude, y = Latitude), 
             nudge_x = -0.2, nudge_y = 0.1, size = 3)
```

Matriz de Correlação das Variáveis
```{r Matriz de correlação}
res <- rcorr(as.matrix(meteo_rj[,3:11]))
corrplot(res$r, 
         type = "upper",
         order="hclust", 
         p.mat = res$P, 
         sig.level = 0.01, 
         insig = "pch")
```

Podemos observar:

- Correlação direta razoável entre Umidade Relativa x Hora;
- Correlação indireta forte entre Umidade Relativa x Temperatura de Bulbo Seco;
- Correlação direta razoável entre Hora x Temperatura de Bulbo Seco;
- Correlação direta forte entre Temperatura de Bulbo Seco e Temperatura de Bulbo Úmido;

## Agregação

Realizaremos as agregação dos dados por dia para agilizar o processamento dos dados.
```{r agregação meteo}
antes <- nrow(meteo_rj)
# Transformanddo em data.table para maior agilidade
meteo_rj <- setDT(meteo_rj)
# Retirando algumas colunas e agregando os dados por dia, utilizando a média do dia.
meteo_rj <- meteo_rj[,-c("Hora", "mes", "ano"), with = FALSE
                          ][, lapply(.SD, mean), by = .(Data, Estacao)]
depois <- nrow(meteo_rj)

sprintf("Redução de %.2f%% após a agregação do dataset.", (depois/antes)*100)
```

## Integração dos Dataframes
O objetivo da integração dos dataframes é reunir em um único dataframe as informações meteorológicas e de focos de incêndio, para cada dia .
A integração dos dois Dataframes será realizada de acordo com o seguinte fluxo:

1. Calcular o raio de alcance de cada estação meteorológica, ou seja, calcular a distância entre cada estação e a estação mais próxima a ela e dividir essa distância por dois.
2. Para cada registro do dataframe meteo:
    * Selecionar todos os focos do dataframe focos que ocorreram no dia do registro;
    * Calcular a distância entre a estação e todos os focos e verificar se eles estão dentro do raio de alcance da estação.
    * Caso positivo, registrar o número de focos em uma nova coluna (n_focos)
    * Caso negativo, registrar 0 focos em uma nova coluna (n_focos)
3. Será criada uma nova coluna "incendio" e caso o registro tenha pelo menos 1 foco, essa coluna receberá "sim", caso contrário, "nao".

```{r integração focos para meteo, eval = FALSE}
# Função principal 
juncao <- function(df_focos, df_meteo=df_meteo, dt_estacoes = NULL){
      if (is.null(dt_estacoes)){
            dt_estacoes <- cria_estacoes(df_meteo)
      }     
      dt_meteo <- setDT(df_meteo)
      dt_focos <- setDT(df_focos)
      dt_focos <- df_focos[,DataHora := as.IDate(DataHora)]
      for (i in 1:nrow(dt_meteo)){
            # para cada obs_meteo calcular se tem um foco dentro do raio da 
            # estacão no dia
            obs_meteo <- dt_meteo[i]
            fdia <- focos_no_dia(obs_meteo, dt_focos)
            if (nrow(fdia) > 0){ 
                  n_focos <- checa_dist(obs_meteo, fdia, dt_estacoes)
            } else {
                  n_focos <- 0
            }
            dt_meteo[i, "n_focos"] <- n_focos 
      }
return(dt_meteo)
}
# Cria tabela das estações e seus raios de ação
cria_estacoes <- function(df_meteo){
      dt_estacoes <- setDT(df_meteo[,c("Estacao", "Longitude", "Latitude")])
      dt_estacoes <- unique(dt_estacoes)
      for (i in 1:nrow(dt_estacoes)){
            dt_estacoes[i,"Raio"] <- cria_raio_estacao(dt_estacoes[i,2:3, 
                                                                  with = FALSE],
                                                       dt_estacoes)
      }
      dt_estacoes <- dt_estacoes[,lapply(.SD, mean), by = .(Estacao)]
      setkey(dt_estacoes, Estacao)
      return(dt_estacoes)
}
# Calcula os raios
cria_raio_estacao <- function(ponto, dt_estacoes){
      matriz <- setattr(as.data.frame(distm(ponto, as.matrix(dt_estacoes[,2:3, 
                                                                with = FALSE])), 
                                      stringsAsFactors=FALSE),
                        "class", "data.table")
      matriz <- matriz[,matriz > 100, with = FALSE]
      idx <- which.min(matriz)
      return(as.numeric(matriz[,..idx])/2)
}
# Separa o focos do referido dia
focos_no_dia <- function(obs_meteo, dt_focos){
      dia <- obs_meteo[,Data]
      return(dt_focos[DataHora == as.IDate(format(dia, "%Y-%m-%d"))])
}
# Calcula a distância e confere se está dentro do raio de ação
checa_dist <- function(obs_meteo, dt_focos, dt_estacoes){
      # extrai número estacao
      estacao <- obs_meteo[,Estacao]
      # checa em estacoes pelas coordenadas da estacao
      coord_estacao <- dt_estacoes[Estacao == estacao, 
                                   c("Longitude", "Latitude"), 
                                   with= FALSE]
      # checa em estacoes pelo raio da estacao
      raio_estacao <- dt_estacoes[Estacao == estacao, Raio]
      # calcula distancias entre todos os focos e a estacao
      matriz <- setattr(
            as.data.frame(distm(coord_estacao, 
                                as.matrix(dt_focos[,c("Longitude", "Latitude"), 
                                                   with = FALSE])), 
                                      stringsAsFactors=FALSE), "class", 
                        "data.table")
      # verifica se existem focos dentro do raio
      n_focos <- sum(matriz <= raio_estacao)
      # caso positivo retorna o número de focos
      return(n_focos)
}

dt_estacoes <- cria_estacoes(meteo_rj)
dt_final <- juncao(focos_rj, meteo_rj, dt_estacoes)
```
```{r carregando dt_final, echo = FALSE}
load(file = "./dados/dt_final.RData")
```
```{r criando colunas dt_final}
# Recriando as colunas mes e ano
dt_final[, c("mes", "ano") := list(as.numeric(format(Data, "%m")), 
                                   as.numeric(format(Data, "%Y")))]
```

Criando a coluna Incêndio:
```{r criando a coluna incendio}
dt_final[, "incendio" := ifelse(n_focos > 0, "sim", "nao")]
dt_final$incendio <- as.factor(dt_final$incendio)
```

Dataset final:
```{r Dataset final}
head(dt_final)
tail(dt_final)
str(dt_final)
summary(dt_final)
```

# Mineração de dados

## Escolha do algoritmo

Para escolhermos o melhor algoritmo a ser utilizado, devemos levar em conta a acurácia do modelo e o tempo necessário para o seu treinamento, pois conforme novas observações forem sendo obtidas e a massa de dados for crescendo o tempo necessário para o treinamento do modelo poderá se tornar algo inexequível e pouco prático. 

Desse modo, utilizaremos o pacote CARET ( __C__ lassification __A__ nd __RE__ gression __T__ raining) para testar todos os métodos de classificação disponíveis no pacote. 

Primeiramente utilizaremos uma versão reduzida do dataset para selecionarmos os algoritmos com base no tempo necessário de treinamento, como o objetivo neste momento é a escolha do algoritmo, utilizaremos uma a versão com classes desbalanceadas mesmo.

```{r Escolha de algoritmo tempo, eval = FALSE}
# Procedimento baseado no script criado por Tobias Kind , disponível em seu github https://github.com/tobigithub/caret-machine-learning
# Criando versão menor do dataset desbalanceado
idx <- sample(nrow(dt_final), 1000)
treino <- dt_final[idx,]

# utilizando a validação cruzada kfold = 10
control <- trainControl(method="cv",
                        number = 10,
                        savePredictions="final", 
                        verboseIter = T,
                        allowParallel = T)

# seleção dos preditores
form <- as.formula("incendio ~ Data+TempBulboSeco+TempBulboUmido+
                   UmidadeRelativa+VelocidadeVento+
                   Nebulosidade+Latitude+Longitude+mes")

# Selecionando todos os métodos de classificação do pacote caret
m <- unique(modelLookup()[modelLookup()$forClas,c(1)])

multi_algo_training <- function(models, control = control, treino = treino)
{
  # algoritmos que são muito lentos
  removeModels <- c("AdaBag", "AdaBoost.M1", "FH.GBML", "pda2", "PenalizedLDA",
                    "GFS.GCCL", "rbf", "RFlda", "nodeHarvest", "ORFsvm", "dwdLinear", "dwdPoly", "gam",
                    "gaussprLinear", "ownn", "sddaLDA", "sddaQDA", "SLAVE", "smda", "snn", "rmda", 
                    "rFerns", "wsrf","ordinalNet","awnb", "awtan","manb","nbDiscrete","nbSearch","tan",
                    "tanSearch","bartMachine","randomGLM", "Rborist", "adaboost")
  
  # removendo os algoritmos lentos da lista
  models <- models[!models %in% removeModels]

  # iniciando cluster para a computação paralela
  cluster <- makePSOCKcluster(detectCores() - 1)
  registerDoParallel(cluster)
  
  # "aquecendo" o algoritmo, caso contrário o primeiro método tem uma performance abaixo do normal
  warmup <-train(form, treino, "rf", trControl = control)
  
  # Função para realizar o treinamento dos algoritmos minimizando os erros que possam ser produzidos no processo.
  trainCall <- function(i) 
  {
    cat("----------------------------------------------------","\n");
    set.seed(123); cat(i," <- loaded\n");
    return(tryCatch(
      t2 <- train(form, treino, (i), trControl = control, metric = "Accuracy"),
      error=function(e) NULL))
  }
  
  # Usando lapply pra rodar tudo para que a função try/catch funcione
  t2 <- lapply(models, trainCall)
  
  # removendo valores NULL, só nos interessa métodos que funcionaram
  t2 <- t2[!sapply(t2, is.null)]
  
  # função que extrai os indicadores de performance do algoritmo
  printCall <- function(i) 
  {
    return(tryCatch(
      {
        cat(sprintf("%-22s",(models[i])))
        cat(round(getTrainPerf(t2[[i]])$TrainAccuracy,4),"\t")
        cat(round(getTrainPerf(t2[[i]])$TrainKappa,4),"\t")
        cat(t2[[i]]$times$everything[3],"\n")},
      error=function(e) NULL))
  }
  
  r2 <- lapply(1:length(t2), printCall)
  
  # fechando o cluster
  stopCluster(cluster); registerDoSEQ();
  
  # pré alocando os tipos de dados
  i = 1; MAX = length(t2);
  x1 <- character() # Name
  x2 <- numeric()   # R2
  x3 <- numeric()   # RMSE
  x4 <- numeric()   # time [s]
  x5 <- character() # long model name
  
  # criando os dados de performance
  for (i in 1:length(t2)) {
    x1[i] <- t2[[i]]$method
    x2[i] <- as.numeric(round(getTrainPerf(t2[[i]])$TrainAccuracy,4))
    x3[i] <- as.numeric(round(getTrainPerf(t2[[i]])$TrainKappa,4))
    x4[i] <- as.numeric(t2[[i]]$times$everything[3])
    x5[i] <- t2[[i]]$modelInfo$label
  }
  
  # criando o data frame
  df1 <- data.frame(x1,x2,x3,x4,x5, stringsAsFactors=FALSE)
  names(df1) <- c("Method", "Accuracy", "Kappa", "Time", "Algo_name")
  return(df1)
}

# pré-carregando todos os pacotes necessários
suppressPackageStartupMessages(ll <-lapply(m, require, character.only = TRUE))

primeira_selecao <- multi_algo_training(m)
```
```{r Carregando primeira selecao, echo = FALSE}
load("./dados/primeira_selecao.rds")
```

Analisando os resultados iniciais
```{r Primeira analise}
qplot(primeira_selecao$Time) + 
  ggtitle("Tempo dos algoritmos") +
  geom_vline(aes(xintercept = median(primeira_selecao$Time)))
summary(primeira_selecao)

# Decis do tempo
print("Decis do tempo")
quantile(x = primeira_selecao$Time, probs = c((1:9)/10))

primeira_selecao[primeira_selecao$Time < median(primeira_selecao$Time),]
```

Eliminando 50% dos algoritmos
```{r Segunda seleção}
qplot(primeira_selecao[primeira_selecao$Time <= median(primeira_selecao$Time),4]) + ggtitle("Tempo dos algoritmos")
segunda_selecao <- primeira_selecao[primeira_selecao$Time <= median(primeira_selecao$Time) & 
                                      primeira_selecao$Accuracy > 0.7, ]
summary(segunda_selecao)

# Decis da acurácia
print("Decis da Acurácia")
quantile(x = segunda_selecao$Accuracy, probs = c((1:9)/10))

# Decis do tempo
print("Decis do tempo")
quantile(x = segunda_selecao$Time, probs = c((1:9)/10))

# Dispersão dos resultados Acurácia x tempo
qplot(y = segunda_selecao$Accuracy, x = segunda_selecao$Time)+
  geom_hline(aes(yintercept = median(segunda_selecao$Accuracy), color = "red")) +
  geom_vline(aes(xintercept = median(segunda_selecao$Time), color = "red"))

```

Selecionando os algoritmos que performaram acima da mediana da acurácia e abaixo da mediana do tempo.
```{r Terceira seleção}
qplot(segunda_selecao[segunda_selecao$Time < median(segunda_selecao$Time),4]) + ggtitle("Tempo dos algoritmos")
terceira_selecao <- segunda_selecao[segunda_selecao$Time < median(segunda_selecao$Time) & 
                                      segunda_selecao$Accuracy > median(segunda_selecao$Accuracy), ]
summary(terceira_selecao)

# Decis da acurácia
print("Decis da Acurácia")
quantile(x = terceira_selecao$Accuracy, probs = c((1:9)/10))

# Decis do tempo
print("Decis do tempo")
quantile(x = terceira_selecao$Time, probs = c((1:9)/10))

# Dispersão dos resultados Acurácia x tempo
qplot(y = terceira_selecao$Accuracy, x = terceira_selecao$Time) + 
  geom_hline(aes(yintercept = mean(terceira_selecao$Accuracy)))
terceira_selecao <- terceira_selecao[-7,]

```

Refinamos até chegar a uma lista de 13 algoritmos rápidos e eficientes.
Vamos testar novamente com o dataset completo desbalanceado para refinar ainda mais a lista.

```{r Segunda análise}
idx <- createDataPartition(dt_final$incendio, p = .75, list = FALSE)
treino1 <- dt_final[idx,]
r3 <- multi_algo_training(terceira_selecao$Method, control = control, treino = treino1)
save(r3, file = "./dados/r3.rds")
load("./dados/r3.rds")
qplot(r3$Time, r3$Accuracy)
qplot(r3$Accuracy)

r3[r3$Time < 10,] %>%
  arrange(desc(Accuracy)) %>%
  top_n(4)

selecaofinal <- r3[r3$Time < 10,] %>%
  arrange(desc(Accuracy)) %>%
  top_n(4) %>%
  .$Method
```

Escolhidos os 4 algoritmos com melhor custo benefício, vamos ao balanceamento das classes.


## Balanceamento das classes

A coluna incendio será a nossa coluna alvo. Desde já, podemos percerber que as classes da nossa coluna alvo está desbalanceada o que poderá interferir na mineração de dados, pois criará um viés  a favor da classe que possui mais observações.

Desse modo, podemos empregar técnicas para balanceamento de classes, como over-sampling e under-sampling. 

No under-sampling selecionamos todas as observações da classe com menor número de observações e selecionamos aleatoriamente uma quantidade igual de observações da outra classe. O problema é que nesse caso podemos perder muita informação da outra classe.

No over-sampling selecionamos todas as observações da classe com maior número de observações e selecionamos aleatoriamente uma quantidade igual de observações da outra classe. O problema é que nesse caso podemos gerar um viés para a classe que tinha menor quantidade de observações no início.

Entre Over e Under Sampling existem dois pacotes chamados SMOTE (Synthetic Minority Over-sampling TEchnique) e ROSE (Random Over-Sampling Examples), que trabalham com over e under-sampling ao mesmo tempo.

O pacote caret nos permite utilizar esses métodos de balanceamento diremente no argumento trainControl


Configurando o método de treino do algoritmo, a função utilizará a validação cruzada com kfold = 10 para escolher os melhores parâmetros automaticamente.

```{r train control}
control_over <- trainControl(method="cv",
                        number = 10,
                        savePredictions="final", classProbs = T,
                        allowParallel = T,
                        sampling = "up")
control_under <- trainControl(method="cv",
                        number = 10,
                        savePredictions="final", classProbs = T,
                        allowParallel = T,
                        sampling = "down")
control_smote <- trainControl(method="cv",
                        number = 10,
                        savePredictions="final", classProbs = T,
                        allowParallel = T,
                        sampling = "smote")
control_rose <- trainControl(method="cv",
                        number = 10,
                        savePredictions="final", classProbs = T,
                        allowParallel = T,
                        sampling = "rose")
```

Fórmula a ser utilizada, ou seja, as variáveis preditoras e a variável predita.
```{r formula}
form <- as.formula("incendio ~ Data+TempBulboSeco+TempBulboUmido+
                         UmidadeRelativa+VelocidadeVento+
                         Nebulosidade+Latitude+Longitude+mes")
```

Foram definidos alguns parâmetros de _tuning_ para o algoritmo, a função _train_ irá tentar ajustar o algoritmo utilizando a métrica "Accuracy", através da validação cruzada com k = 10.
```{r train, eval=T}
idx <- createDataPartition(dt_final$incendio, p = .75, list = FALSE)
treino1 <- dt_final[idx,]
metric <- "Accuracy"

over <- multi_algo_training(selecaofinal, control = control_over, treino = treino1)
under <- multi_algo_training(selecaofinal, control = control_under, treino = treino1)
smote <- multi_algo_training(selecaofinal, control = control_smote, treino = treino1)
rose <- multi_algo_training(selecaofinal, control = control_rose, treino = treino1)


```

Resultados de diferentes parametrizações:
```{r sumario do fit, echo=F}
fit
```

# __Interpretação e Avaliação__

O seguinte gráfico mostra o a acurácia em relação aos diferentes parâmetros utilizados durante o ajuste.
```{r plot parâmetros modelo}
plot(fit)
```

Gráfico mostrando a importância de cada variável para a predição.
```{r importância das variáveis}
ggplot(varImp(fit)) + theme_minimal()
```

A partir desse modelo final vamos testar com o dataset "teste" que foi separado no início da análise.

```{r Matriz confusão, options}
pred <- predict(fit, teste)
mat_conf <- confusionMatrix(pred, reference = teste$incendio, 
                            positive = "sim",
                            mode = "prec_recall")
mat_conf
```

De acordo com a matriz de confusão:

- O algoritmo teve uma acurácia de 85,09%, isto é, acertou 85% das previsões no geral;
- 54,39% de sensibilidade; classificou como "sim" 54,39% dos eventos que realmente eram "sim";
- 76,29% de precisão; 76,29% dos eventos classificados como "sim", realmente eram "sim"
- 94,7% de especificidade; classificou como "nao" 94,7% dos eventos que realmente eram "nao";

Essa diferença se deve ao fato das classes estarem desbalanceadas no dataset original, esse desbalanceamento é medido pela prevalência, que representa a proporção do valor positivo, no caso "sim", em relação à quantidade valores negativos, "nao". Para o nosso dataset de teste a prevalência está em 23,86%.

Outro ponto a ser observado é que a maior parte das predições errôneas ocorreram em estações do centro-oeste e norte do país, e que a quantidade de estações nessas áres é relativamente baixa em relação a outras áreas do país.
```{r mapa desempenho por estacao, options}
figure2+ 
      geom_count(data = cbind(teste, pred)[,acerto := ifelse(incendio==pred, "sim", "nao")], 
       aes(x=Longitude, y=Latitude, color = acerto, size = ..prop..), show.legend = T) + 
      scale_size_area(max_size = 5) + theme_bw() +
      scale_color_brewer(type = "div",direction = 1, palette = "Spectral")

data.table(cbind(teste, pred)[,acerto := ifelse(incendio==pred, "sim", "nao")])

```